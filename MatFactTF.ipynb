{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MF_RS():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda=0.01, conf_lambda=1.0, conf_dim = 1):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = np.min([200000, numUsers, numSongs]);\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 20\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.conf_lambda = conf_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        if conf_dim > 0:\n",
    "            self.C_user = tf.Variable(.5*tf.ones([numUsers, conf_dim]))\n",
    "            self.C_song = tf.Variable(.5*tf.ones([numSongs, conf_dim]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        # bias\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        # confidence params\n",
    "        if conf_dim > 0:\n",
    "            self.C_ui = tf.clip_by_value(tf.nn.embedding_lookup(self.C_user, self.users), 1e-20, 1-1e-20)\n",
    "            self.C_sj = tf.clip_by_value(tf.nn.embedding_lookup(self.C_song, self.songs), 1e-20, 1-1e-20)\n",
    "\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "            \n",
    "        # l2 reg\n",
    "        if conf_dim > 0:\n",
    "            self.confidence_reg = self.conf_lambda * tf.reduce_sum(1-self.C_ui + 1-self.C_sj)\n",
    "            #self.confidence_reg = self.conf_lambda * tf.reduce_sum(-tf.log(self.C_ui) + -tf.log(self.C_sj))\n",
    "        self.l2_reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                         tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)))\n",
    "        if conf_dim > 0:\n",
    "            self.reg = self.l2_reg + self.confidence_reg\n",
    "        else:\n",
    "            self.reg = self.l2_reg\n",
    "        #self.yhat_capped = self.yhat\n",
    "        #self.yhat_capped[self.rating == 5] = tf.minimum(self.yhat_capped, 5)[self.rating == 5]\n",
    "        #self.yhat_capped[self.rating == 0.5] = tf.maximum(self.yhat_capped, 0.5)[self.rating == 0.5]\n",
    "        if conf_dim > 0:\n",
    "             self.error = tf.reduce_mean(tf.reduce_sum(self.C_ui * self.C_sj, 1) *\n",
    "                                         tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        else:\n",
    "            self.error = tf.reduce_mean(tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = (self.error + self.reg)/1e7\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())    \n",
    "        \n",
    "    def train(self, users, songs, ratings, verb = 0):\n",
    "        for i in range(self.epochs):\n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "\n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                if verb > 2:\n",
    "                    avg_cost += self.session.run([self.U, self.W],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "            if verb > 0:\n",
    "                print(avg_cost/num_batches)\n",
    "                \n",
    "    def test(self, users, songs):\n",
    "        yhat = np.zeros(len(users))\n",
    "        num_batches = len(users) // self.batch_size\n",
    "        for b_idx in range(num_batches):\n",
    "            batch = range(self.batch_size * b_idx,self.batch_size * (b_idx + 1))\n",
    "            users_batch = users[batch]\n",
    "            songs_batch = songs[batch]\n",
    "            yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        batch = range(-self.batch_size,0)\n",
    "        users_batch = users[batch]\n",
    "        songs_batch = songs[batch]\n",
    "        yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        return yhat\n",
    "    \n",
    "    def evaluate(self, users, songs, ratings):\n",
    "        yhat = self.test(users, songs)\n",
    "        yhat = np.clip(yhat, a_min = 0.5, a_max = 5)\n",
    "        return np.mean((yhat - ratings)**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([4, 3, 2, 5, 1])\n",
    "#unique users / songs\n",
    "uni_a = np.unique(a)\n",
    "uni_b = np.unique(b)\n",
    "\n",
    "#dict mapping the id to an index\n",
    "a_map = dict(zip(uni_a,range(len(uni_a))))\n",
    "b_map = dict(zip(uni_b,range(len(uni_b))))\n",
    "\n",
    "user_idx =  np.array([ a_map[user] for user in a])\n",
    "song_idx =  np.array([ b_map[song] for song in b])\n",
    "model = MF_RS(len(uni_a), len(uni_b), 7)\n",
    "np.random.seed(2)\n",
    "model.epochs = 2\n",
    "model.train(user_idx, song_idx, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movieratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_real_user = np.max(movieratings['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_ids = np.unique(movieratings['movieId'])\n",
    "movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "random.choice([1,2,3,6,10,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fake_id=[]\n",
    "all_fake_movie=[]\n",
    "all_fake_rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "rating_options = np.linspace(0.5, 5, 10)\n",
    "movie_count_fake_user=2000\n",
    "for fake_idx in range(1,101):\n",
    "    fake_UID = fake_idx + max_real_user\n",
    "    fake_user_mouse = random.choice(rating_options)\n",
    "    for i in range(movie_count_fake_user):\n",
    "        movie_id = random.choice(movie_ids)\n",
    "        rating = fake_user_mouse\n",
    "        if np.random.rand() > 0.8:\n",
    "            fake_user_mouse = random.choice(rating_options)\n",
    "        # propagate\n",
    "        all_fake_id.append(fake_UID)\n",
    "        all_fake_movie.append(movie_id)\n",
    "        all_fake_rating.append(rating)\n",
    "fake_df = pd.DataFrame({\"movieId\":all_fake_movie, \"userId\":all_fake_id, \"rating\":all_fake_rating})\n",
    "\n",
    "combo_df = pd.concat([movieratings.drop(\"timestamp\",1),fake_df])\n",
    "\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combo_df[combo_df.userId == 771]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combo_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe(include = 'all').T\n",
    "    var = pd.DataFrame(data = {'nanvals': pd.Series(), 'number_distinct': pd.Series()})\n",
    "    for i in range(len(input_data.columns)):\n",
    "        nanvals = input_data.ix[:,i].isnull().sum()\n",
    "        number_distinct = len(input_data.ix[:,i].value_counts())\n",
    "        var = var.append(pd.DataFrame([[nanvals, number_distinct]], columns = ['nanvals', 'number_distinct']))\n",
    "    var.index = output_data.index.values\n",
    "    output_data['nanvals'] = var['nanvals']\n",
    "    output_data['number_distinct'] = var['number_distinct']\n",
    "    return output_data\n",
    "output_data = getDfSummary(movieratings)\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = movieratings.ix[np.random.permutation(len(movieratings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = movieratings.ix[:,0].values\n",
    "songs = movieratings.ix[:,1].values\n",
    "ratings = movieratings.ix[:,2].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users = movieratings['userId'].unique()\n",
    "uni_songs = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map = dict(zip(uni_users,range(len(uni_users))))\n",
    "song_map = dict(zip(uni_songs,range(len(uni_songs))))\n",
    "\n",
    "user_idx =  np.array([ user_map[user] for user in users])\n",
    "song_idx =  np.array([ song_map[song] for song in songs])\n",
    "\n",
    "print(len(uni_users),len(uni_songs))\n",
    "\n",
    "perm = range(len(users))#np.random.permutation(len(users))\n",
    "trn_idx = perm[:(len(users)*2)//3]\n",
    "val_idx = perm[(len(users)*2)//3:]\n",
    "user_idx_trn, song_idx_trn, ratings_trn = user_idx[trn_idx], song_idx[trn_idx], ratings[trn_idx]\n",
    "user_idx_val, song_idx_val, ratings_val = user_idx[val_idx], song_idx[val_idx], ratings[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_with_noise = combo_df.ix[:,\"userId\"].values\n",
    "songs_with_noise = combo_df.ix[:,\"movieId\"].values\n",
    "ratings_with_noise = combo_df.ix[:,\"rating\"].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users_with_noise = combo_df['userId'].unique()\n",
    "uni_songs_with_noise = combo_df['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map_with_noise = dict(zip(uni_users_with_noise,range(len(uni_users_with_noise))))\n",
    "song_map_with_noise = dict(zip(uni_songs_with_noise,range(len(uni_songs_with_noise))))\n",
    "\n",
    "user_idx_with_noise =  np.array([ user_map_with_noise[user] for user in users_with_noise])\n",
    "song_idx_with_noise =  np.array([ song_map_with_noise[song] for song in songs_with_noise])\n",
    "\n",
    "print(len(uni_users_with_noise),len(uni_songs_with_noise))\n",
    "\n",
    "perm_with_noise = range(len(users_with_noise))#np.random.permutation(len(users_with_noise))\n",
    "trn_idx_with_noise = list(trn_idx)+list(range(len(users), len(users_with_noise)))#perm_with_noise[:(len(users_with_noise)*2)//3]\n",
    "val_idx_with_noise = list(val_idx)#perm_with_noise[(len(users_with_noise)*2)//3:]\n",
    "user_idx_trn_with_noise, song_idx_trn_with_noise, ratings_trn_with_noise = \\\n",
    "        user_idx_with_noise[trn_idx_with_noise], song_idx_with_noise[trn_idx_with_noise], \\\n",
    "        ratings_with_noise[trn_idx_with_noise]\n",
    "user_idx_val_with_noise, song_idx_val_with_noise, ratings_val_with_noise =\\\n",
    "        user_idx_with_noise[val_idx_with_noise], song_idx_with_noise[val_idx_with_noise],\\\n",
    "        ratings_with_noise[val_idx_with_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "reg_l = 0.01\n",
    "conf_l = .1\n",
    "conf = 3\n",
    "edim = 5\n",
    "songmodel = MF_RS(len (uni_users), len(uni_songs), embedding_dim = edim, \n",
    "                  reg_lambda=reg_l, conf_lambda=conf_l, conf_dim = conf)\n",
    "print(songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "songmodel.epochs = 1\n",
    "songmodel.train(user_idx_trn, song_idx_trn, ratings_trn, verb = 3)\n",
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edims = [5, 7]\n",
    "confs = [0, 2]\n",
    "errmat = np.zeros([len(edims), len(confs)])\n",
    "reg_l = 1\n",
    "conf_l = 1000\n",
    "for eidx, edim in enumerate(edims):\n",
    "    for cidx, conf in enumerate(confs):\n",
    "        songmodel = MF_RS(len (uni_users), len(uni_songs), edim, \n",
    "                          reg_lambda=reg_l, conf_lambda=conf_l, conf_dim = conf)\n",
    "        print(\"accuracy before training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "        np.random.seed(1)\n",
    "        songmodel.epochs = 20\n",
    "        #songmodel.train(user_idx_trn_with_noise, song_idx_trn_with_noise, ratings_trn_with_noise)\n",
    "        songmodel.train(user_idx_trn, song_idx_trn, ratings_trn)\n",
    "        err = songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)\n",
    "        print(\"accuracy after training with edim \", edim, \" and confidence dim \", conf, \": \", err)\n",
    "        errmat[eidx, cidx] = err\n",
    "errmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edims = [5, 7]\n",
    "confs = [0, 2]\n",
    "errmat = np.zeros([len(edims), len(confs)])\n",
    "reg_l = 1\n",
    "conf_l = 10\n",
    "for eidx, edim in enumerate(edims):\n",
    "    for cidx, conf in enumerate(confs):\n",
    "        songmodel = MF_RS(len (uni_users_with_noise), len(uni_songs_with_noise), edim, \n",
    "                          reg_lambda=reg_l, conf_lambda=conf_l, conf_dim = conf)\n",
    "        print(\"Error before training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "        np.random.seed(1)\n",
    "        songmodel.epochs = 50\n",
    "        songmodel.train(user_idx_trn_with_noise, song_idx_trn_with_noise, ratings_trn_with_noise)\n",
    "        #songmodel.train(user_idx_trn, song_idx_trn, ratings_trn)\n",
    "        err = songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)\n",
    "        print(\"Error after training with edim \", edim, \" and confidence dim \", conf, \": \", err)\n",
    "        errmat[eidx, cidx] = err\n",
    "errmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
